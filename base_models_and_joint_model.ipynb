{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3-75Og1XMfj1",
        "UZvoZaaNEtS-",
        "GLwVCbwlh7ER",
        "lXVypdkoylkI",
        "eQyj7DHQh-nX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57ed9e25ba254d83982e82c85a2071ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4361243c625f4aa7aade185b044058b2",
              "IPY_MODEL_f8c9615e7f724539999f3d71ae40c899",
              "IPY_MODEL_af957c702eba40eba2725489f7198cff"
            ],
            "layout": "IPY_MODEL_e99af71eff4d4c1888b21f0d93709918"
          }
        },
        "4361243c625f4aa7aade185b044058b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b42db2d0f9642dd995db45a565e0a80",
            "placeholder": "​",
            "style": "IPY_MODEL_711d29bae2b8498d85b1dca7546b0619",
            "value": "Downloading: 100%"
          }
        },
        "f8c9615e7f724539999f3d71ae40c899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d51381cad8d548b689222d5e1d187aab",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f65085cbc5e048688506545cc25e949a",
            "value": 898823
          }
        },
        "af957c702eba40eba2725489f7198cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe6035d59b1b4dd6a252e68b6a161f8e",
            "placeholder": "​",
            "style": "IPY_MODEL_1cb33c5d25454cf4a2a43e1514bd8710",
            "value": " 899k/899k [00:00&lt;00:00, 1.58MB/s]"
          }
        },
        "e99af71eff4d4c1888b21f0d93709918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b42db2d0f9642dd995db45a565e0a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711d29bae2b8498d85b1dca7546b0619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d51381cad8d548b689222d5e1d187aab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65085cbc5e048688506545cc25e949a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe6035d59b1b4dd6a252e68b6a161f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb33c5d25454cf4a2a43e1514bd8710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17263dc75b794dea908b017fde45bf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec79ec83b7044b9dab81720ca724a430",
              "IPY_MODEL_d9b1e5882fe74969b6aee981a94df6cb",
              "IPY_MODEL_a95fae8ee7a840fbb319e2f79923030a"
            ],
            "layout": "IPY_MODEL_7f078f64e8a64020bc56baa66a7bdcca"
          }
        },
        "ec79ec83b7044b9dab81720ca724a430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa79ae278136494ebaa66937332c8493",
            "placeholder": "​",
            "style": "IPY_MODEL_f8c18f4d32c64bcfa75857e04e1ddd46",
            "value": "Downloading: 100%"
          }
        },
        "d9b1e5882fe74969b6aee981a94df6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a8f0708e824c3a85acb9476ebe7248",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1624ea160823411aa97b120f6a7dc598",
            "value": 456318
          }
        },
        "a95fae8ee7a840fbb319e2f79923030a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb97a3d109e4f6ca46964a3bb44e23d",
            "placeholder": "​",
            "style": "IPY_MODEL_93f650f2373346edaac17c258481223e",
            "value": " 456k/456k [00:00&lt;00:00, 1.36MB/s]"
          }
        },
        "7f078f64e8a64020bc56baa66a7bdcca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa79ae278136494ebaa66937332c8493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c18f4d32c64bcfa75857e04e1ddd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0a8f0708e824c3a85acb9476ebe7248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1624ea160823411aa97b120f6a7dc598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eb97a3d109e4f6ca46964a3bb44e23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f650f2373346edaac17c258481223e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ebad64985a445b80110b108a739370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0fc66c0a7f24cdcbdc04295076a0b02",
              "IPY_MODEL_9a1bcb3632dc4bb69ddc3d0337984387",
              "IPY_MODEL_4461e4fceb944779a0bf468ed931bd32"
            ],
            "layout": "IPY_MODEL_0627f1685c4049f19a49027fa09a392d"
          }
        },
        "d0fc66c0a7f24cdcbdc04295076a0b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4152990e665f429da81e14c3eac4aba0",
            "placeholder": "​",
            "style": "IPY_MODEL_cf6d5c97b37d4791a57c4edb51e8452e",
            "value": "Downloading: 100%"
          }
        },
        "9a1bcb3632dc4bb69ddc3d0337984387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b54268bf60824820943678862c7c44d8",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f971eab0350c4f37905c664041c12ae2",
            "value": 1355863
          }
        },
        "4461e4fceb944779a0bf468ed931bd32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d35e2e2eec8f4deebc55eb7cb954bc55",
            "placeholder": "​",
            "style": "IPY_MODEL_b0ce906b4ff1403da427625a886ce0d7",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.99MB/s]"
          }
        },
        "0627f1685c4049f19a49027fa09a392d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4152990e665f429da81e14c3eac4aba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf6d5c97b37d4791a57c4edb51e8452e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b54268bf60824820943678862c7c44d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f971eab0350c4f37905c664041c12ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d35e2e2eec8f4deebc55eb7cb954bc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ce906b4ff1403da427625a886ce0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e7387b54e92483f853af48727a79a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c22bde94d92a4714b51b0647db69df0e",
              "IPY_MODEL_447e5ab3329b4fcaa916468e18cd1576",
              "IPY_MODEL_896bd2b5998e41a9a167663543fc3611"
            ],
            "layout": "IPY_MODEL_b77bfacbab764c50ad57dd8b6d8b8181"
          }
        },
        "c22bde94d92a4714b51b0647db69df0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f6479c0466427e9e1cefe90be256c1",
            "placeholder": "​",
            "style": "IPY_MODEL_58e0f5d5d5ca445e83b69d88b1b8166a",
            "value": "Downloading: 100%"
          }
        },
        "447e5ab3329b4fcaa916468e18cd1576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c1a4cfd7a0c4da4969094e425d07802",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_661363e0474546a98a7d077e2d5aa0fc",
            "value": 481
          }
        },
        "896bd2b5998e41a9a167663543fc3611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b42f1b051c47faa7e4f2f6c7f48c0b",
            "placeholder": "​",
            "style": "IPY_MODEL_ab831fcde945474c9a38871fa30ab01a",
            "value": " 481/481 [00:00&lt;00:00, 4.91kB/s]"
          }
        },
        "b77bfacbab764c50ad57dd8b6d8b8181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f6479c0466427e9e1cefe90be256c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e0f5d5d5ca445e83b69d88b1b8166a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c1a4cfd7a0c4da4969094e425d07802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661363e0474546a98a7d077e2d5aa0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31b42f1b051c47faa7e4f2f6c7f48c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab831fcde945474c9a38871fa30ab01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4170070dd35549009ff93ebead5f45fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd4dc5bdbd114879a37359c63d04ab15",
              "IPY_MODEL_829d151349b54c599beab743e7bb62e4",
              "IPY_MODEL_9c2c98f8e2814fbe806e89681dd562ab"
            ],
            "layout": "IPY_MODEL_5f4b0713d24c407389a27c87aa0668c6"
          }
        },
        "bd4dc5bdbd114879a37359c63d04ab15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c52b9741cb04b03a3f2782767ee5a89",
            "placeholder": "​",
            "style": "IPY_MODEL_8895ff9e63b44591be18867f921af89e",
            "value": "Downloading: 100%"
          }
        },
        "829d151349b54c599beab743e7bb62e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63528cde9ab94eab90b673af1ffaa39f",
            "max": 657434796,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8dd41e6249c435b8d8c8edff13a8881",
            "value": 657434796
          }
        },
        "9c2c98f8e2814fbe806e89681dd562ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a2813edd4c48b18fecf3dff5dde030",
            "placeholder": "​",
            "style": "IPY_MODEL_54ab347e69e04f159b239aae9a497749",
            "value": " 657M/657M [00:12&lt;00:00, 31.3MB/s]"
          }
        },
        "5f4b0713d24c407389a27c87aa0668c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c52b9741cb04b03a3f2782767ee5a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8895ff9e63b44591be18867f921af89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63528cde9ab94eab90b673af1ffaa39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8dd41e6249c435b8d8c8edff13a8881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89a2813edd4c48b18fecf3dff5dde030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54ab347e69e04f159b239aae9a497749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py\n",
        "!pip install transformers\n",
        "!pip install scipy\n",
        "from transformers import RobertaTokenizerFast\n",
        "from transformers import TFRobertaModel\n",
        "import tensorflow as tf\n",
        "from transformers import RobertaTokenizer, RobertaModel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh62jSfLPW6x",
        "outputId": "58270444-ddb3-4690-a4b3-986643e07135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 69.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7dthQvybNdX",
        "outputId": "3bac046a-6235-4215-f08c-878ce9e8dd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "worksheet = gc.open('PennsylvaniaMidterms11Aug11Oct2').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "import pandas as pd\n",
        "df=pd.DataFrame.from_records(rows)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r9a_SGGRqHus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_header = df.iloc[0] #grab the first row for the header\n",
        "df = df[1:] #take the data less the header row\n",
        "df.columns = new_header #set the header row as the df header"
      ],
      "metadata": {
        "id": "r32bqgSGIu9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# df = pd.read_excel('/content/drive/MyDrive/NLP_Project/labelled_test.xlsx')"
      ],
      "metadata": {
        "id": "ajv2duP9bRvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SentimentScore']= pd.to_numeric(df['SentimentScore'])\n",
        "df['Subjectivity']= pd.to_numeric(df['Subjectivity'])\n",
        "df['Sarcasm']= pd.to_numeric(df['Sarcasm'])\n",
        "df['Faction']= pd.to_numeric(df['Faction'])\n",
        "final_df=df.loc[df['SentimentScore'].isin([0,1,2])]"
      ],
      "metadata": {
        "id": "1NEDDq94ay9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set seed"
      ],
      "metadata": {
        "id": "iEFHMbPHkq-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "import random \n",
        "random.seed(SEED)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "W0UuC52mksYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data preprocessing"
      ],
      "metadata": {
        "id": "n-6qS8l1HsMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "DiS2H2cibIXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_content(content):\n",
        "  content=re.sub('#','',content)\n",
        "  content = re.sub(r'@[^(JohnFetterman)][^(DrOz)]\\w+', '', content)\n",
        "  content = re.sub('@', '', content)\n",
        "  content = re.sub(r'\\\\u\\w+', '', content)\n",
        "  content = re.sub(r\"http\\S+\", \"\", content)\n",
        "  content = re.sub(\"\\n\", \"\", content)\n",
        "  # content = re.sub(r'[^\\w\\s\\.]', '', content)\n",
        "  # content=' '.join(s for s in content.split() if not any(c.isdigit() for c in s))\n",
        "  # content=content.lower()\n",
        "  return content\n"
      ],
      "metadata": {
        "id": "VnfNpbMNa3BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['cleaned_tweets']=final_df['Content'].apply(clean_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eXMNbepp93M",
        "outputId": "843433c3-0d7d-461f-f108-f4611a55685e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRyZB4WR5hCS",
        "outputId": "c89da92a-9671-456f-b38a-0b58ae08a27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def nltk2wn_tag(nltk_tag):\n",
        "  if nltk_tag.startswith('J'):\n",
        "    return wordnet.ADJ\n",
        "  elif nltk_tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif nltk_tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif nltk_tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:                    \n",
        "    return None\n",
        "def lemmatize_sentence(content,lemmatizer=lemmatizer):\n",
        "  nltk_tagged = nltk.pos_tag(nltk.word_tokenize(content))    \n",
        "  wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
        "  res_words = []\n",
        "  for word, tag in wn_tagged:\n",
        "    if tag is None:             \n",
        "      res_words.append(word.lower())\n",
        "    else:\n",
        "      res_words.append(lemmatizer.lemmatize(word.lower(), tag))\n",
        "  content=\" \".join(res_words)\n",
        "  content = re.sub(r'[^\\w\\s]', '', content)\n",
        "  content=' '.join(s for s in content.split() if not any(c.isdigit() for c in s))\n",
        "  return content"
      ],
      "metadata": {
        "id": "g_n3mpuT0Mal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['lemmatized_tweets']=final_df['cleaned_tweets'].apply(lemmatize_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SXfMr835CUb",
        "outputId": "0ff22c78-4502-4724-8670-b5bdd3d5c791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "yL-YX30FJUCk",
        "outputId": "f9d39ef5-521e-4c57-fc3d-a98e611b7834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                          Date  \\\n",
              "1     2022-10-08 15:43:14+00:00   \n",
              "2     2022-09-23 21:35:23+00:00   \n",
              "3     2022-09-23 18:46:26+00:00   \n",
              "4     2022-09-23 16:04:47+00:00   \n",
              "5     2022-09-23 13:37:39+00:00   \n",
              "...                         ...   \n",
              "1513  2022-08-31 17:45:43+00:00   \n",
              "1517  2022-08-31 16:04:29+00:00   \n",
              "1525  2022-08-31 04:45:49+00:00   \n",
              "1548  2022-08-30 05:35:45+00:00   \n",
              "1559  2022-08-29 20:18:35+00:00   \n",
              "\n",
              "0                                               Content                       \\\n",
              "1     VOTE FOR @JohnFetterman .\\nRepublican @DrOz  w...  1578773016908951554   \n",
              "2     @the_vello Why does he always look like a SLOB...  1573425822970568709   \n",
              "3     John Fetterman is a POS! Just a trust found ki...  1573383305566846976   \n",
              "4     @DrOz I would love to see a sit-down, face-to-...  1573342622877626369   \n",
              "5     Baphomet is non binary and babies were slain f...  1573305596190904321   \n",
              "...                                                 ...                  ...   \n",
              "1513  #JohnFetterman stroke recovery is absolutely f...  1565033103860572162   \n",
              "1517  @NRSC_Rapid @JohnFetterman @DrOz Continuing hi...  1565007625900752898   \n",
              "1525  @sahilkapur @JohnFetterman @DrOz I think #John...  1564836833397067776   \n",
              "1548  He's a real winner, isn't he? #JohnFetterman i...  1564487012811476995   \n",
              "1559  @DrOz I'm sorry but that guy is dealing with t...  1564346799279726592   \n",
              "\n",
              "0                                                           \\\n",
              "1     Richard79300111  0  0   1  0  1578773016908951554      \n",
              "2          sgtmolly06  0  0   6  0  1573419293273907211      \n",
              "3          aizenlorde  0  1   1  0  1573383305566846976      \n",
              "4     darthbanish_EP2  0  0   1  0  1573342057321619456      \n",
              "5           Nanaof313  0  0   3  0  1573305596190904321      \n",
              "...               ... .. ..  .. ..                  ... ..   \n",
              "1513        MarkDavis  4  0  22  1  1565033103860572162      \n",
              "1517   SnowyEvergreen  0  0   0  0  1564325011007176708      \n",
              "1525   StopEndWarsNOW  0  0   0  0  1564758762115719169      \n",
              "1548         rlburson  1  0   1  0  1564487012811476995      \n",
              "1559    SandyDivsalar  0  0   1  0  1564314941422817285      \n",
              "\n",
              "0                                                                  \\\n",
              "1     https://twitter.com/JohnFetterman/status/15787...             \n",
              "2                                                        1.57E+18   \n",
              "3                                                                   \n",
              "4                                                        1.57E+18   \n",
              "5                                                                   \n",
              "...                                                 ...       ...   \n",
              "1513  https://twitter.com/TomBevanRCP/status/1565030...             \n",
              "1517                                                     1.56E+18   \n",
              "1525                                                     1.56E+18   \n",
              "1548  https://twitter.com/RNCResearch/status/1564418...             \n",
              "1559                                                     1.56E+18   \n",
              "\n",
              "0                                     \\\n",
              "1                                      \n",
              "2      https://twitter.com/the_vello   \n",
              "3                                      \n",
              "4           https://twitter.com/DrOz   \n",
              "5                                      \n",
              "...                              ...   \n",
              "1513                                   \n",
              "1517  https://twitter.com/NRSC_Rapid   \n",
              "1525  https://twitter.com/sahilkapur   \n",
              "1548                                   \n",
              "1559        https://twitter.com/DrOz   \n",
              "\n",
              "0                                                        SentimentScore  \\\n",
              "1     [User(username='JohnFetterman', id=3622368202,...             0.0   \n",
              "2     [User(username='the_vello', id=93330058, displ...             0.0   \n",
              "3                                                                   0.0   \n",
              "4     [User(username='DrOz', id=38531995, displaynam...             0.0   \n",
              "5                                                                   0.0   \n",
              "...                                                 ...             ...   \n",
              "1513                                                                2.0   \n",
              "1517  [User(username='NRSC_Rapid', id=13592192524615...             2.0   \n",
              "1525  [User(username='sahilkapur', id=19847765, disp...             2.0   \n",
              "1548                                                                0.0   \n",
              "1559  [User(username='DrOz', id=38531995, displaynam...             2.0   \n",
              "\n",
              "0     Subjectivity  Sarcasm  Faction  \\\n",
              "1              1.0      1.0      1.0   \n",
              "2              1.0      0.0      1.0   \n",
              "3              1.0      1.0      1.0   \n",
              "4              1.0      1.0      1.0   \n",
              "5              1.0      0.0      1.0   \n",
              "...            ...      ...      ...   \n",
              "1513           0.0      NaN      2.0   \n",
              "1517           0.0      NaN      1.0   \n",
              "1525           0.0      NaN      1.0   \n",
              "1548           1.0      1.0      1.0   \n",
              "1559           0.0      NaN      1.0   \n",
              "\n",
              "0                                        cleaned_tweets  \\\n",
              "1     VOTE FOR JohnFetterman .Republican DrOz  will ...   \n",
              "2     the_vello Why does he always look like a SLOB?...   \n",
              "3     John Fetterman is a POS! Just a trust found ki...   \n",
              "4     DrOz I would love to see a sit-down, face-to-f...   \n",
              "5     Baphomet is non binary and babies were slain f...   \n",
              "...                                                 ...   \n",
              "1513  JohnFetterman stroke recovery is absolutely fa...   \n",
              "1517   JohnFetterman DrOz Continuing his campaign on...   \n",
              "1525   JohnFetterman DrOz I think JohnFetterman shou...   \n",
              "1548  He's a real winner, isn't he? JohnFetterman is...   \n",
              "1559  DrOz I'm sorry but that guy is dealing with th...   \n",
              "\n",
              "0                                     lemmatized_tweets  \n",
              "1     vote for johnfetterman republican droz will no...  \n",
              "2     the_vello why do he always look like a slob he...  \n",
              "3     john fetterman be a po just a trust find kid w...  \n",
              "4     droz i would love to see a sitdown facetoface ...  \n",
              "5     baphomet be non binary and baby be slay for mo...  \n",
              "...                                                 ...  \n",
              "1513  johnfetterman stroke recovery be absolutely fa...  \n",
              "1517  johnfetterman droz continue his campaign only ...  \n",
              "1525  johnfetterman droz i think johnfetterman shoul...  \n",
              "1548  he s a real winner be nt he johnfetterman be b...  \n",
              "1559  droz i m sorry but that guy be deal with the a...  \n",
              "\n",
              "[1051 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7751cdc7-3731-4176-927f-474bc0a7c303\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Content</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>SentimentScore</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Faction</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>lemmatized_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-08 15:43:14+00:00</td>\n",
              "      <td>VOTE FOR @JohnFetterman .\\nRepublican @DrOz  w...</td>\n",
              "      <td>1578773016908951554</td>\n",
              "      <td>Richard79300111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1578773016908951554</td>\n",
              "      <td></td>\n",
              "      <td>https://twitter.com/JohnFetterman/status/15787...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[User(username='JohnFetterman', id=3622368202,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>VOTE FOR JohnFetterman .Republican DrOz  will ...</td>\n",
              "      <td>vote for johnfetterman republican droz will no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-23 21:35:23+00:00</td>\n",
              "      <td>@the_vello Why does he always look like a SLOB...</td>\n",
              "      <td>1573425822970568709</td>\n",
              "      <td>sgtmolly06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1573419293273907211</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.57E+18</td>\n",
              "      <td>https://twitter.com/the_vello</td>\n",
              "      <td>[User(username='the_vello', id=93330058, displ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the_vello Why does he always look like a SLOB?...</td>\n",
              "      <td>the_vello why do he always look like a slob he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-23 18:46:26+00:00</td>\n",
              "      <td>John Fetterman is a POS! Just a trust found ki...</td>\n",
              "      <td>1573383305566846976</td>\n",
              "      <td>aizenlorde</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1573383305566846976</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>John Fetterman is a POS! Just a trust found ki...</td>\n",
              "      <td>john fetterman be a po just a trust find kid w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-23 16:04:47+00:00</td>\n",
              "      <td>@DrOz I would love to see a sit-down, face-to-...</td>\n",
              "      <td>1573342622877626369</td>\n",
              "      <td>darthbanish_EP2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1573342057321619456</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.57E+18</td>\n",
              "      <td>https://twitter.com/DrOz</td>\n",
              "      <td>[User(username='DrOz', id=38531995, displaynam...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>DrOz I would love to see a sit-down, face-to-f...</td>\n",
              "      <td>droz i would love to see a sitdown facetoface ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-23 13:37:39+00:00</td>\n",
              "      <td>Baphomet is non binary and babies were slain f...</td>\n",
              "      <td>1573305596190904321</td>\n",
              "      <td>Nanaof313</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1573305596190904321</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Baphomet is non binary and babies were slain f...</td>\n",
              "      <td>baphomet be non binary and baby be slay for mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>2022-08-31 17:45:43+00:00</td>\n",
              "      <td>#JohnFetterman stroke recovery is absolutely f...</td>\n",
              "      <td>1565033103860572162</td>\n",
              "      <td>MarkDavis</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1565033103860572162</td>\n",
              "      <td></td>\n",
              "      <td>https://twitter.com/TomBevanRCP/status/1565030...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>JohnFetterman stroke recovery is absolutely fa...</td>\n",
              "      <td>johnfetterman stroke recovery be absolutely fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>2022-08-31 16:04:29+00:00</td>\n",
              "      <td>@NRSC_Rapid @JohnFetterman @DrOz Continuing hi...</td>\n",
              "      <td>1565007625900752898</td>\n",
              "      <td>SnowyEvergreen</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1564325011007176708</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.56E+18</td>\n",
              "      <td>https://twitter.com/NRSC_Rapid</td>\n",
              "      <td>[User(username='NRSC_Rapid', id=13592192524615...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>JohnFetterman DrOz Continuing his campaign on...</td>\n",
              "      <td>johnfetterman droz continue his campaign only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525</th>\n",
              "      <td>2022-08-31 04:45:49+00:00</td>\n",
              "      <td>@sahilkapur @JohnFetterman @DrOz I think #John...</td>\n",
              "      <td>1564836833397067776</td>\n",
              "      <td>StopEndWarsNOW</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1564758762115719169</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.56E+18</td>\n",
              "      <td>https://twitter.com/sahilkapur</td>\n",
              "      <td>[User(username='sahilkapur', id=19847765, disp...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>JohnFetterman DrOz I think JohnFetterman shou...</td>\n",
              "      <td>johnfetterman droz i think johnfetterman shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1548</th>\n",
              "      <td>2022-08-30 05:35:45+00:00</td>\n",
              "      <td>He's a real winner, isn't he? #JohnFetterman i...</td>\n",
              "      <td>1564487012811476995</td>\n",
              "      <td>rlburson</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1564487012811476995</td>\n",
              "      <td></td>\n",
              "      <td>https://twitter.com/RNCResearch/status/1564418...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>He's a real winner, isn't he? JohnFetterman is...</td>\n",
              "      <td>he s a real winner be nt he johnfetterman be b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1559</th>\n",
              "      <td>2022-08-29 20:18:35+00:00</td>\n",
              "      <td>@DrOz I'm sorry but that guy is dealing with t...</td>\n",
              "      <td>1564346799279726592</td>\n",
              "      <td>SandyDivsalar</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1564314941422817285</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.56E+18</td>\n",
              "      <td>https://twitter.com/DrOz</td>\n",
              "      <td>[User(username='DrOz', id=38531995, displaynam...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>DrOz I'm sorry but that guy is dealing with th...</td>\n",
              "      <td>droz i m sorry but that guy be deal with the a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1051 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7751cdc7-3731-4176-927f-474bc0a7c303')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7751cdc7-3731-4176-927f-474bc0a7c303 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7751cdc7-3731-4176-927f-474bc0a7c303');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# metric"
      ],
      "metadata": {
        "id": "0XXK1Ihx52wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#see result\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "def get_result(target,pred):\n",
        "  '''returns accuracy, f1, precision, recall'''\n",
        "  return accuracy_score(target,pred),f1_score(target,pred,average='weighted'),precision_score(target,pred),recall_score(target,pred)\n"
      ],
      "metadata": {
        "id": "K9hXjdv26Bh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train test split and subjectivity detection"
      ],
      "metadata": {
        "id": "3-75Og1XMfj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_roberta = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "def tokenize_roberta(data,max_len=128,tokenizer_roberta=tokenizer_roberta) :\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(data)):\n",
        "        encoded = tokenizer_roberta.encode_plus(\n",
        "            data[i],\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    return np.array(input_ids),np.array(attention_masks)"
      ],
      "metadata": {
        "id": "F6vmenIQPzmp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "57ed9e25ba254d83982e82c85a2071ad",
            "4361243c625f4aa7aade185b044058b2",
            "f8c9615e7f724539999f3d71ae40c899",
            "af957c702eba40eba2725489f7198cff",
            "e99af71eff4d4c1888b21f0d93709918",
            "3b42db2d0f9642dd995db45a565e0a80",
            "711d29bae2b8498d85b1dca7546b0619",
            "d51381cad8d548b689222d5e1d187aab",
            "f65085cbc5e048688506545cc25e949a",
            "fe6035d59b1b4dd6a252e68b6a161f8e",
            "1cb33c5d25454cf4a2a43e1514bd8710",
            "17263dc75b794dea908b017fde45bf7f",
            "ec79ec83b7044b9dab81720ca724a430",
            "d9b1e5882fe74969b6aee981a94df6cb",
            "a95fae8ee7a840fbb319e2f79923030a",
            "7f078f64e8a64020bc56baa66a7bdcca",
            "aa79ae278136494ebaa66937332c8493",
            "f8c18f4d32c64bcfa75857e04e1ddd46",
            "f0a8f0708e824c3a85acb9476ebe7248",
            "1624ea160823411aa97b120f6a7dc598",
            "6eb97a3d109e4f6ca46964a3bb44e23d",
            "93f650f2373346edaac17c258481223e",
            "83ebad64985a445b80110b108a739370",
            "d0fc66c0a7f24cdcbdc04295076a0b02",
            "9a1bcb3632dc4bb69ddc3d0337984387",
            "4461e4fceb944779a0bf468ed931bd32",
            "0627f1685c4049f19a49027fa09a392d",
            "4152990e665f429da81e14c3eac4aba0",
            "cf6d5c97b37d4791a57c4edb51e8452e",
            "b54268bf60824820943678862c7c44d8",
            "f971eab0350c4f37905c664041c12ae2",
            "d35e2e2eec8f4deebc55eb7cb954bc55",
            "b0ce906b4ff1403da427625a886ce0d7",
            "9e7387b54e92483f853af48727a79a71",
            "c22bde94d92a4714b51b0647db69df0e",
            "447e5ab3329b4fcaa916468e18cd1576",
            "896bd2b5998e41a9a167663543fc3611",
            "b77bfacbab764c50ad57dd8b6d8b8181",
            "79f6479c0466427e9e1cefe90be256c1",
            "58e0f5d5d5ca445e83b69d88b1b8166a",
            "2c1a4cfd7a0c4da4969094e425d07802",
            "661363e0474546a98a7d077e2d5aa0fc",
            "31b42f1b051c47faa7e4f2f6c7f48c0b",
            "ab831fcde945474c9a38871fa30ab01a"
          ]
        },
        "outputId": "7a06d3fa-3df4-42df-a292-b3902bf06b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57ed9e25ba254d83982e82c85a2071ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17263dc75b794dea908b017fde45bf7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83ebad64985a445b80110b108a739370"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e7387b54e92483f853af48727a79a71"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def roberta_model(bert_model, max_len=128):\n",
        "    \n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    output = bert_model([input_ids,attention_masks])\n",
        "    output = output[1]\n",
        "    output = tf.keras.layers.Dense(128, activation='relu')(output)\n",
        "    output = tf.keras.layers.Dense(1)(output)\n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
        "    model.compile(opt, loss=loss, metrics=accuracy)\n",
        "    return model"
      ],
      "metadata": {
        "id": "SPHlhnydP8CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#five fold X validation\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "\n",
        "skf=KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "best_model = roberta_model(roberta)\n",
        "best_a=0\n",
        "for train_index, test_index in skf.split(final_df['cleaned_tweets'].values,final_df['Subjectivity'].values):\n",
        "  X_train, X_test = final_df['cleaned_tweets'].values[train_index], final_df['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = final_df['Subjectivity'].values[train_index], final_df['Subjectivity'].values[test_index]\n",
        "  roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "  r_model = roberta_model(roberta)\n",
        "  train_input_ids, train_attention_masks = tokenize_roberta(X_train, 128)\n",
        "  test_input_ids, test_attention_masks = tokenize_roberta(X_test, 128)\n",
        "  history = r_model.fit([train_input_ids,train_attention_masks], y_train, epochs=4, batch_size=32)\n",
        "  result_roberta = r_model.predict([test_input_ids,test_attention_masks])\n",
        "  result_roberta=tf.math.sigmoid(result_roberta)\n",
        "  result_roberta=tf.reshape(result_roberta,(result_roberta.shape[0],)).numpy()\n",
        "  y_pred=[]\n",
        "  for i in result_roberta:\n",
        "    if i<=0.5:\n",
        "      y_pred.append(0)\n",
        "\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  if a > best_a:\n",
        "    best_model=r_model\n",
        "    best_a=a\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)\n",
        "\n",
        "best_model.save_weights('/content/drive/MyDrive/model/subjectivity.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4170070dd35549009ff93ebead5f45fc",
            "bd4dc5bdbd114879a37359c63d04ab15",
            "829d151349b54c599beab743e7bb62e4",
            "9c2c98f8e2814fbe806e89681dd562ab",
            "5f4b0713d24c407389a27c87aa0668c6",
            "7c52b9741cb04b03a3f2782767ee5a89",
            "8895ff9e63b44591be18867f921af89e",
            "63528cde9ab94eab90b673af1ffaa39f",
            "c8dd41e6249c435b8d8c8edff13a8881",
            "89a2813edd4c48b18fecf3dff5dde030",
            "54ab347e69e04f159b239aae9a497749"
          ]
        },
        "id": "Lib0c9bML5Jr",
        "outputId": "5378413d-52ad-4771-adb6-922a3690b2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/657M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4170070dd35549009ff93ebead5f45fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "27/27 [==============================] - 50s 727ms/step - loss: 0.6454 - binary_accuracy: 0.4571\n",
            "Epoch 2/4\n",
            "27/27 [==============================] - 20s 726ms/step - loss: 0.3341 - binary_accuracy: 0.8929\n",
            "Epoch 3/4\n",
            "27/27 [==============================] - 20s 744ms/step - loss: 0.2913 - binary_accuracy: 0.8988\n",
            "Epoch 4/4\n",
            "27/27 [==============================] - 20s 743ms/step - loss: 0.2152 - binary_accuracy: 0.9155\n",
            "7/7 [==============================] - 4s 242ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "27/27 [==============================] - 36s 749ms/step - loss: 0.5578 - binary_accuracy: 0.5600\n",
            "Epoch 2/4\n",
            "27/27 [==============================] - 21s 761ms/step - loss: 0.3549 - binary_accuracy: 0.8811\n",
            "Epoch 3/4\n",
            "27/27 [==============================] - 21s 769ms/step - loss: 0.3010 - binary_accuracy: 0.8847\n",
            "Epoch 4/4\n",
            "27/27 [==============================] - 21s 762ms/step - loss: 0.2216 - binary_accuracy: 0.9132\n",
            "7/7 [==============================] - 4s 238ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "27/27 [==============================] - 36s 760ms/step - loss: 0.4486 - binary_accuracy: 0.7111\n",
            "Epoch 2/4\n",
            "27/27 [==============================] - 21s 769ms/step - loss: 0.3362 - binary_accuracy: 0.8918\n",
            "Epoch 3/4\n",
            "27/27 [==============================] - 21s 765ms/step - loss: 0.3032 - binary_accuracy: 0.8918\n",
            "Epoch 4/4\n",
            "27/27 [==============================] - 21s 759ms/step - loss: 0.2631 - binary_accuracy: 0.8918\n",
            "7/7 [==============================] - 4s 238ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "27/27 [==============================] - 36s 763ms/step - loss: 0.3913 - binary_accuracy: 0.8930\n",
            "Epoch 2/4\n",
            "27/27 [==============================] - 21s 775ms/step - loss: 0.3356 - binary_accuracy: 0.8930\n",
            "Epoch 3/4\n",
            "27/27 [==============================] - 21s 760ms/step - loss: 0.2931 - binary_accuracy: 0.8930\n",
            "Epoch 4/4\n",
            "27/27 [==============================] - 20s 757ms/step - loss: 0.2344 - binary_accuracy: 0.9001\n",
            "7/7 [==============================] - 4s 238ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "27/27 [==============================] - 37s 767ms/step - loss: 0.4648 - binary_accuracy: 0.6968\n",
            "Epoch 2/4\n",
            "27/27 [==============================] - 21s 776ms/step - loss: 0.3378 - binary_accuracy: 0.8894\n",
            "Epoch 3/4\n",
            "27/27 [==============================] - 21s 763ms/step - loss: 0.3149 - binary_accuracy: 0.8894\n",
            "Epoch 4/4\n",
            "27/27 [==============================] - 21s 760ms/step - loss: 0.2695 - binary_accuracy: 0.8954\n",
            "7/7 [==============================] - 4s 240ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "id": "RyhMyuszTBHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2008c27e-6985-4741-9b9c-8ebeaae5bc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8924937937260212, f1: 0.8635544260166454, precision: 0.9138093631514683, recall: 0.9734745054332684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# textblob subjectivity"
      ],
      "metadata": {
        "id": "UZvoZaaNEtS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def getSubjectivity(review):\n",
        "    return TextBlob(review).sentiment.subjectivity"
      ],
      "metadata": {
        "id": "i-QV6qwZEw85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblob_sub=final_df['cleaned_tweets'].apply(getSubjectivity)"
      ],
      "metadata": {
        "id": "inGFX-EgTs-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for i in textblob_sub:\n",
        "  if i<=0.5:\n",
        "    y_pred.append(0)\n",
        "\n",
        "  else:\n",
        "    y_pred.append(1)"
      ],
      "metadata": {
        "id": "8uoA6vQqT4zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_result(final_df['Subjectivity'].values,y_pred))"
      ],
      "metadata": {
        "id": "Bl5aZ9xQVMI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f381006c-2b24-4e74-e280-6c35e5431457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.3939105613701237, 0.4729389734252783, 0.9257142857142857, 0.34652406417112297)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get raw sentiment"
      ],
      "metadata": {
        "id": "_LM6vrzPUVOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment=final_df[final_df['SentimentScore']<2]\n",
        "sentiment=sentiment[sentiment['Faction']<2]\n",
        "sentiment=sentiment.dropna(subset=['Faction'])\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "qmsmH_PGUXMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support=sentiment['SentimentScore'].values\n",
        "faction=sentiment['Faction'].values\n",
        "raw_sent=[]\n",
        "for i in range(len(faction)):\n",
        "  if faction[i]==2:\n",
        "    raw_sent.append(support[i])\n",
        "  elif faction[i]!=support[i]:\n",
        "    if support[i]==0:\n",
        "      raw_sent.append(1)\n",
        "    else:\n",
        "      raw_sent.append(0)\n",
        "  else:\n",
        "    raw_sent.append(support[i])"
      ],
      "metadata": {
        "id": "6depHLloW4GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nltk"
      ],
      "metadata": {
        "id": "GLwVCbwlh7ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "CvT4Lps7cMA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "5SBes8sYgriY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8ffd39-26ec-48ba-829d-b3fcaa0871b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nltk_sent(content):\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  if sia.polarity_scores(content)['pos'] > sia.polarity_scores(content)['neg']:\n",
        "    s=1\n",
        "  else:\n",
        "    s=0\n",
        "  return s"
      ],
      "metadata": {
        "id": "w3jxsswLb2zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_score=sentiment['cleaned_tweets'].apply(nltk_sent)\n",
        "print(get_result(raw_sent,nltk_score))"
      ],
      "metadata": {
        "id": "v2TrfifdgPzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bcf3a2-c3f5-4418-c77d-5cd6d646d57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.4737991266375546, 0.47581874007643227, 0.7350993377483444, 0.3557692307692308)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_score=sentiment['lemmatized_tweets'].apply(nltk_sent)\n",
        "print(get_result(raw_sent,nltk_score))"
      ],
      "metadata": {
        "id": "SqiBtki-7hHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15405418-ddeb-4fd6-e788-7258ede3574d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.47925764192139736, 0.4853893450161035, 0.7261538461538461, 0.3782051282051282)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#textblob"
      ],
      "metadata": {
        "id": "lXVypdkoylkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def text_score(content):\n",
        "  if TextBlob(content).sentiment[1]<=0.5:\n",
        "    s=0\n",
        "  else:\n",
        "    s=1\n",
        "  return s"
      ],
      "metadata": {
        "id": "KS8Ur0I6yoPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_score=sentiment['cleaned_tweets'].apply(text_score)\n",
        "print(get_result(raw_sent,txt_score))"
      ],
      "metadata": {
        "id": "mOljf2uazC4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdae6bb-226d-4883-bb6c-b738d3fafd6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.42248908296943233, 0.4277756197127178, 0.6498422712933754, 0.3301282051282051)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_score=sentiment['lemmatized_tweets'].apply(text_score)\n",
        "print(get_result(raw_sent,txt_score))"
      ],
      "metadata": {
        "id": "-5JRnUZq8HK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2ac2f1-459c-44c9-cf2e-90174297fbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.45087336244541487, 0.4617403947682731, 0.6713881019830028, 0.3798076923076923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#roberta on raw sentiment"
      ],
      "metadata": {
        "id": "eQyj7DHQh-nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.module import register_module_full_backward_hook\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "best_model = roberta_model(roberta)\n",
        "best_a=0\n",
        "for train_index, test_index in skf.split(sentiment['cleaned_tweets'].values,np.array(raw_sent)):\n",
        "  X_train, X_test = sentiment['cleaned_tweets'].values[train_index], sentiment['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = np.array(raw_sent)[train_index], np.array(raw_sent)[test_index]\n",
        "  roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "  r_model = roberta_model(roberta)\n",
        "  train_input_ids, train_attention_masks = tokenize_roberta(X_train, 128)\n",
        "  test_input_ids, test_attention_masks = tokenize_roberta(X_test, 128)\n",
        "  history = r_model.fit([train_input_ids,train_attention_masks], y_train, epochs=5, batch_size=32)\n",
        "  result_roberta = r_model.predict([test_input_ids,test_attention_masks])\n",
        "  result_roberta=tf.math.sigmoid(result_roberta)\n",
        "  result_roberta=tf.reshape(result_roberta,(result_roberta.shape[0],)).numpy()\n",
        "  y_pred=[]\n",
        "  for i in result_roberta:\n",
        "    if i<=0.5:\n",
        "      y_pred.append(0)\n",
        "\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  if a > best_a:\n",
        "    best_model=r_model\n",
        "    best_a=a\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)"
      ],
      "metadata": {
        "id": "A1KNDqNQZ4HK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f72d9ad-ac84-498a-a695-654dec0e247b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 35s 779ms/step - loss: 0.6480 - binary_accuracy: 0.5301\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 18s 794ms/step - loss: 0.5987 - binary_accuracy: 0.7049\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 18s 785ms/step - loss: 0.4258 - binary_accuracy: 0.8224\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 18s 775ms/step - loss: 0.2987 - binary_accuracy: 0.8798\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 18s 777ms/step - loss: 0.2098 - binary_accuracy: 0.9249\n",
            "6/6 [==============================] - 4s 245ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 33s 783ms/step - loss: 0.6496 - binary_accuracy: 0.5211\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 18s 793ms/step - loss: 0.5914 - binary_accuracy: 0.7258\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 18s 782ms/step - loss: 0.4021 - binary_accuracy: 0.8240\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 18s 775ms/step - loss: 0.2778 - binary_accuracy: 0.8840\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 18s 778ms/step - loss: 0.2167 - binary_accuracy: 0.9100\n",
            "6/6 [==============================] - 4s 244ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 33s 786ms/step - loss: 0.6560 - binary_accuracy: 0.4625\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 18s 796ms/step - loss: 0.6172 - binary_accuracy: 0.6862\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 18s 782ms/step - loss: 0.5097 - binary_accuracy: 0.7804\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 18s 776ms/step - loss: 0.3185 - binary_accuracy: 0.8649\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 18s 779ms/step - loss: 0.2404 - binary_accuracy: 0.9045\n",
            "6/6 [==============================] - 4s 243ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 34s 782ms/step - loss: 0.6164 - binary_accuracy: 0.6494\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 18s 795ms/step - loss: 0.5892 - binary_accuracy: 0.7394\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 18s 782ms/step - loss: 0.4442 - binary_accuracy: 0.8186\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 18s 775ms/step - loss: 0.3019 - binary_accuracy: 0.8799\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 18s 778ms/step - loss: 0.2289 - binary_accuracy: 0.9031\n",
            "6/6 [==============================] - 4s 247ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 34s 780ms/step - loss: 0.6216 - binary_accuracy: 0.5457\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 18s 796ms/step - loss: 0.5791 - binary_accuracy: 0.7462\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 18s 785ms/step - loss: 0.3599 - binary_accuracy: 0.8554\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 18s 776ms/step - loss: 0.2708 - binary_accuracy: 0.8990\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 18s 777ms/step - loss: 0.1998 - binary_accuracy: 0.9168\n",
            "6/6 [==============================] - 4s 243ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save_weights('/content/drive/MyDrive/sentiment_model/sentiment.h5')"
      ],
      "metadata": {
        "id": "wGaLbw9ZLvuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "id": "wTh9Js3qbDcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095c7640-7368-4537-f1eb-02ba0b3c5e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.863512710857686, f1: 0.8595363800645522, precision: 0.8694842177908539, recall: 0.9411400225083423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# svm using tfidf on raw sentiment"
      ],
      "metadata": {
        "id": "fzIr-CPZQJ90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "best_model=svm.SVC()\n",
        "best_a=0\n",
        "for train_index, test_index in skf.split(sentiment['cleaned_tweets'].values,np.array(raw_sent)):\n",
        "  X_train, X_test = sentiment['cleaned_tweets'].values[train_index], sentiment['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = np.array(raw_sent)[train_index], np.array(raw_sent)[test_index]\n",
        "  train_vectors = vectorizer.fit_transform(X_train)\n",
        "  test_vectors = vectorizer.transform(X_test)\n",
        "  model = svm.SVC()\n",
        "  y_pred = model.fit(train_vectors, y_train).predict(test_vectors)\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  if a > best_a:\n",
        "    best_model=model\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)\n"
      ],
      "metadata": {
        "id": "h0A_lGlfQNSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB_WfeYndcLZ",
        "outputId": "8b7521b6-891e-4ebd-c8bd-2712a2ce6817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7936029935851746, f1: 0.7742883171238215, precision: 0.7898194732239047, recall: 0.9507284711176863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "for train_index, test_index in skf.split(sentiment['lemmatized_tweets'].values,np.array(raw_sent)):\n",
        "  X_train, X_test = sentiment['lemmatized_tweets'].values[train_index], sentiment['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = np.array(raw_sent)[train_index], np.array(raw_sent)[test_index]\n",
        "  train_vectors = vectorizer.fit_transform(X_train)\n",
        "  test_vectors = vectorizer.transform(X_test)\n",
        "  model = svm.SVC()\n",
        "  y_pred = model.fit(train_vectors, y_train).predict(test_vectors)\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)"
      ],
      "metadata": {
        "id": "dGT99-Z48-xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwgJsSmGdmY4",
        "outputId": "c333e00d-4930-4123-967b-9e3974c4ba9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7805238774055595, f1: 0.7598698817675446, precision: 0.7811246735760168, recall: 0.9432684955612254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# another naive bayes on raw sentiment"
      ],
      "metadata": {
        "id": "up2VrBsetI2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {}\n",
        "    self.num_words = 0\n",
        "\n",
        "  def add_word(self, word):\n",
        "    if word not in self.word2index:\n",
        "      # First entry of word into vocabulary\n",
        "      self.word2index[word] = self.num_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.num_words] = word\n",
        "      self.num_words += 1\n",
        "    else:\n",
        "      # Word exists; increase word count\n",
        "      self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "zYO504NyjCEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "vocab=Vocabulary('tweet')\n",
        "for i in sentiment['lemmatized_tweets']:\n",
        "  result=wordpunct_tokenize(i)\n",
        "  for j in result:\n",
        "    vocab.add_word(j)\n",
        "def vectorize(input,vocab=vocab):\n",
        "  master_list=[]\n",
        "  for i in input:\n",
        "    result=wordpunct_tokenize(i)\n",
        "    tweet=[0]*len(vocab.word2index)\n",
        "    for j in result:\n",
        "      for k in vocab.word2index:\n",
        "        if j==k:\n",
        "          tweet[vocab.word2index[j]]=1\n",
        "    master_list.append(tweet)\n",
        "  return master_list\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "best_model=MultinomialNB()\n",
        "best_a=0\n",
        "for train_index, test_index in skf.split(sentiment['lemmatized_tweets'].values,np.array(raw_sent)):\n",
        "  X_train, X_test = sentiment['lemmatized_tweets'].values[train_index], sentiment['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = np.array(raw_sent)[train_index], np.array(raw_sent)[test_index]\n",
        "  train_vectors = vectorize(X_train)\n",
        "  test_vectors = vectorize(X_test)\n",
        "  model = MultinomialNB()\n",
        "  y_pred = model.fit(vectorize(X_train), y_train).predict(vectorize(X_test))\n",
        "  if a > best_a:\n",
        "    best_a=a\n",
        "    best_model=model\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)"
      ],
      "metadata": {
        "id": "rwsOQV0Oks7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmvurlC1eF2Z",
        "outputId": "702f0a87-54bb-4c79-e8fe-3e12751812e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7390413399857448, f1: 0.7043353372445881, precision: 0.7455220447137336, recall: 0.9377429445889724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# roberta on support"
      ],
      "metadata": {
        "id": "xsS4e6JojyOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_df=final_df[final_df['SentimentScore']<2]"
      ],
      "metadata": {
        "id": "N5KywUGgcmZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "for train_index, test_index in skf.split(support_df['cleaned_tweets'].values,support_df['SentimentScore'].values):\n",
        "  X_train, X_test = support_df['cleaned_tweets'].values[train_index], support_df['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = support_df['SentimentScore'].values[train_index], support_df['SentimentScore'].values[test_index]\n",
        "  roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "  r_model = roberta_model(roberta)\n",
        "  train_input_ids, train_attention_masks = tokenize_roberta(X_train, 128)\n",
        "  test_input_ids, test_attention_masks = tokenize_roberta(X_test, 128)\n",
        "  history = r_model.fit([train_input_ids,train_attention_masks], y_train, epochs=4, batch_size=32)\n",
        "  result_roberta = r_model.predict([test_input_ids,test_attention_masks])\n",
        "  result_roberta=tf.math.sigmoid(result_roberta)\n",
        "  result_roberta=tf.reshape(result_roberta,(result_roberta.shape[0],)).numpy()\n",
        "  y_pred=[]\n",
        "  for i in result_roberta:\n",
        "    if i<=0.5:\n",
        "      y_pred.append(0)\n",
        "\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y8tnF_Hj4wY",
        "outputId": "5b054a01-e662-4d57-9978-ba497c606708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "24/24 [==============================] - 33s 765ms/step - loss: 0.6829 - binary_accuracy: 0.4439\n",
            "Epoch 2/4\n",
            "24/24 [==============================] - 19s 778ms/step - loss: 0.6466 - binary_accuracy: 0.5401\n",
            "Epoch 3/4\n",
            "24/24 [==============================] - 18s 765ms/step - loss: 0.4797 - binary_accuracy: 0.7861\n",
            "Epoch 4/4\n",
            "24/24 [==============================] - 18s 758ms/step - loss: 0.3397 - binary_accuracy: 0.8556\n",
            "6/6 [==============================] - 4s 249ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "24/24 [==============================] - 34s 762ms/step - loss: 0.6799 - binary_accuracy: 0.4425\n",
            "Epoch 2/4\n",
            "24/24 [==============================] - 19s 777ms/step - loss: 0.6161 - binary_accuracy: 0.6818\n",
            "Epoch 3/4\n",
            "24/24 [==============================] - 18s 768ms/step - loss: 0.4354 - binary_accuracy: 0.7995\n",
            "Epoch 4/4\n",
            "24/24 [==============================] - 18s 760ms/step - loss: 0.3467 - binary_accuracy: 0.8556\n",
            "6/6 [==============================] - 4s 249ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "24/24 [==============================] - 34s 760ms/step - loss: 0.6817 - binary_accuracy: 0.4666\n",
            "Epoch 2/4\n",
            "24/24 [==============================] - 19s 775ms/step - loss: 0.6152 - binary_accuracy: 0.6684\n",
            "Epoch 3/4\n",
            "24/24 [==============================] - 19s 771ms/step - loss: 0.3797 - binary_accuracy: 0.8329\n",
            "Epoch 4/4\n",
            "24/24 [==============================] - 18s 759ms/step - loss: 0.2233 - binary_accuracy: 0.9104\n",
            "6/6 [==============================] - 4s 248ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "24/24 [==============================] - 34s 760ms/step - loss: 0.6976 - binary_accuracy: 0.4826\n",
            "Epoch 2/4\n",
            "24/24 [==============================] - 19s 776ms/step - loss: 0.6126 - binary_accuracy: 0.6725\n",
            "Epoch 3/4\n",
            "24/24 [==============================] - 18s 768ms/step - loss: 0.3866 - binary_accuracy: 0.8262\n",
            "Epoch 4/4\n",
            "24/24 [==============================] - 18s 760ms/step - loss: 0.2636 - binary_accuracy: 0.9011\n",
            "6/6 [==============================] - 4s 248ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "24/24 [==============================] - 34s 760ms/step - loss: 0.6857 - binary_accuracy: 0.4519\n",
            "Epoch 2/4\n",
            "24/24 [==============================] - 19s 778ms/step - loss: 0.6531 - binary_accuracy: 0.6070\n",
            "Epoch 3/4\n",
            "24/24 [==============================] - 18s 768ms/step - loss: 0.4872 - binary_accuracy: 0.7741\n",
            "Epoch 4/4\n",
            "24/24 [==============================] - 18s 759ms/step - loss: 0.3390 - binary_accuracy: 0.8489\n",
            "6/6 [==============================] - 5s 252ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ebRxH2skgXW",
        "outputId": "823b8406-6dee-4cda-ad42-3842e5e4d684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8481283422459892, f1: 0.8440870269988702, precision: 0.8266458135228467, recall: 0.9322577412560127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# naive bayes on support"
      ],
      "metadata": {
        "id": "3f69MFhOlkOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=Vocabulary('tweet')\n",
        "for i in support_df['lemmatized_tweets']:\n",
        "  result=wordpunct_tokenize(i)\n",
        "  for j in result:\n",
        "    vocab.add_word(j)\n",
        "def vectorize(input,vocab=vocab):\n",
        "  master_list=[]\n",
        "  for i in input:\n",
        "    result=wordpunct_tokenize(i)\n",
        "    tweet=[0]*len(vocab.word2index)\n",
        "    for j in result:\n",
        "      for k in vocab.word2index:\n",
        "        if j==k:\n",
        "          tweet[vocab.word2index[j]]=1\n",
        "    master_list.append(tweet)\n",
        "  return master_list\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "for train_index, test_index in skf.split(support_df['lemmatized_tweets'].values,support_df['SentimentScore'].values):\n",
        "  X_train, X_test = support_df['lemmatized_tweets'].values[train_index], support_df['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = support_df['SentimentScore'].values[train_index], support_df['SentimentScore'].values[test_index]\n",
        "  train_vectors = vectorize(X_train)\n",
        "  test_vectors = vectorize(X_test)\n",
        "  model = MultinomialNB()\n",
        "  y_pred = model.fit(vectorize(X_train), y_train).predict(vectorize(X_test))\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)"
      ],
      "metadata": {
        "id": "KKyxve_UlU0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urQaywo9nDkm",
        "outputId": "17853613-c8a3-4e33-f11c-dfed2f6cb104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.722994652406417, f1: 0.7249684008325369, precision: 0.7957523446795765, recall: 0.6887192909425766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# svm on support"
      ],
      "metadata": {
        "id": "zoCnwdZSl7MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "\n",
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "for train_index, test_index in skf.split(support_df['lemmatized_tweets'].values,support_df['SentimentScore'].values):\n",
        "  X_train, X_test = support_df['lemmatized_tweets'].values[train_index], support_df['lemmatized_tweets'].values[test_index]\n",
        "  y_train, y_test = support_df['SentimentScore'].values[train_index], support_df['SentimentScore'].values[test_index]\n",
        "  train_vectors = vectorizer.fit_transform(X_train)\n",
        "  test_vectors = vectorizer.transform(X_test)\n",
        "  model = svm.SVC()\n",
        "  y_pred = model.fit(train_vectors, y_train).predict(test_vectors)\n",
        "  a,b,c,d=get_result(y_test,y_pred)\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)"
      ],
      "metadata": {
        "id": "UK04p1W-mEK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKkt3JI4mgD4",
        "outputId": "fda9691c-7d99-4282-ab7e-c9978ddfee22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8513368983957219, f1: 0.8506125382496192, precision: 0.8436342178750277, recall: 0.9048092478431446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# roberta on joint and aspect based"
      ],
      "metadata": {
        "id": "iVsP4vapngvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_model(bert_model, max_len=128):\n",
        "    \n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
        "    loss = {\n",
        "\t\"Faction\": tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "\t\"RawSentiment\": tf.keras.losses.BinaryCrossentropy(from_logits=True)}\n",
        "    lossWeights = {\"Faction\": 1.0, \"RawSentiment\": 1.0}\n",
        "    accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n",
        "    output = bert_model([input_ids,attention_masks])\n",
        "    output = output[1]\n",
        "    output = tf.keras.layers.Dense(128, activation='relu')(output)\n",
        "    faction = tf.keras.layers.Dense(1,name='Faction')(output)\n",
        "    sentiment = tf.keras.layers.Dense(1,name='RawSentiment')(output)\n",
        "    output=[faction,sentiment]\n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
        "    model.compile(opt, loss=loss, metrics=accuracy, loss_weights=lossWeights)\n",
        "    return model"
      ],
      "metadata": {
        "id": "S92gnOqQoanH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_df=sentiment[['cleaned_tweets','Faction']]\n",
        "joint_df['RawSentiment']=raw_sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWrdrpV3qrSg",
        "outputId": "71703444-75da-4a42-96de-62e0f7b9e614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=[]\n",
        "f1=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "\n",
        "accuracy_s=[]\n",
        "f1_s=[]\n",
        "precision_s=[]\n",
        "recall_s=[]\n",
        "roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "best_model=joint_model(roberta)\n",
        "best_a=0\n",
        "for train_index, test_index in skf.split(joint_df['cleaned_tweets'].values,joint_df['Faction'].values):\n",
        "  X_train, X_test = joint_df['cleaned_tweets'].values[train_index], joint_df['cleaned_tweets'].values[test_index]\n",
        "  y_train, y_test = {'Faction':joint_df['Faction'].values[train_index], 'RawSentiment': joint_df['RawSentiment'].values[train_index]},{'Faction':joint_df['Faction'].values[test_index],'RawSentiment':joint_df['RawSentiment'].values[test_index]}\n",
        "  roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "  r_model = joint_model(roberta)\n",
        "  train_input_ids, train_attention_masks = tokenize_roberta(X_train, 128)\n",
        "  test_input_ids, test_attention_masks = tokenize_roberta(X_test, 128)\n",
        "  history = r_model.fit([train_input_ids,train_attention_masks], y_train, epochs=4, batch_size=32)\n",
        "  result= r_model.predict([test_input_ids,test_attention_masks])\n",
        "  f,s=result[0],result[1]\n",
        "  f,s=tf.math.sigmoid(f),tf.math.sigmoid(s)\n",
        "  f,s=tf.reshape(f,(f.shape[0],)).numpy(),tf.reshape(s,(s.shape[0],)).numpy()\n",
        "\n",
        "  y_pred=[]\n",
        "  for i in f:\n",
        "    if i<=0.5:\n",
        "      y_pred.append(0)\n",
        "\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "  a,b,c,d=get_result(y_test['Faction'],y_pred)\n",
        "  accuracy.append(a)\n",
        "  f1.append(b)\n",
        "  precision.append(c)\n",
        "  recall.append(d)\n",
        "  if a>best_a:\n",
        "    best_a=a\n",
        "    best_model=r_model\n",
        "\n",
        "  y_pred=[]\n",
        "  for i in s:\n",
        "    if i<=0.5:\n",
        "      y_pred.append(0)\n",
        "\n",
        "    else:\n",
        "      y_pred.append(1)\n",
        "  a,b,c,d=get_result(y_test['RawSentiment'],y_pred)\n",
        "  accuracy_s.append(a)\n",
        "  f1_s.append(b)\n",
        "  precision_s.append(c)\n",
        "  recall_s.append(d)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTk0F13hngCJ",
        "outputId": "e17ab882-207b-4f61-80cc-ce20e1e9a8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "23/23 [==============================] - 35s 777ms/step - loss: 1.3357 - Faction_loss: 0.6764 - RawSentiment_loss: 0.6593 - Faction_binary_accuracy: 0.4139 - RawSentiment_binary_accuracy: 0.4344\n",
            "Epoch 2/4\n",
            "23/23 [==============================] - 18s 795ms/step - loss: 1.2387 - Faction_loss: 0.6219 - RawSentiment_loss: 0.6167 - Faction_binary_accuracy: 0.7172 - RawSentiment_binary_accuracy: 0.7117\n",
            "Epoch 3/4\n",
            "23/23 [==============================] - 18s 784ms/step - loss: 0.9261 - Faction_loss: 0.4710 - RawSentiment_loss: 0.4552 - Faction_binary_accuracy: 0.8060 - RawSentiment_binary_accuracy: 0.8060\n",
            "Epoch 4/4\n",
            "23/23 [==============================] - 18s 777ms/step - loss: 0.6324 - Faction_loss: 0.3164 - RawSentiment_loss: 0.3160 - Faction_binary_accuracy: 0.8866 - RawSentiment_binary_accuracy: 0.8770\n",
            "6/6 [==============================] - 6s 247ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "23/23 [==============================] - 35s 786ms/step - loss: 1.2683 - Faction_loss: 0.6306 - RawSentiment_loss: 0.6378 - Faction_binary_accuracy: 0.5689 - RawSentiment_binary_accuracy: 0.5225\n",
            "Epoch 2/4\n",
            "23/23 [==============================] - 18s 795ms/step - loss: 1.0974 - Faction_loss: 0.5480 - RawSentiment_loss: 0.5494 - Faction_binary_accuracy: 0.7640 - RawSentiment_binary_accuracy: 0.7681\n",
            "Epoch 3/4\n",
            "23/23 [==============================] - 18s 787ms/step - loss: 0.7060 - Faction_loss: 0.3547 - RawSentiment_loss: 0.3513 - Faction_binary_accuracy: 0.8472 - RawSentiment_binary_accuracy: 0.8458\n",
            "Epoch 4/4\n",
            "23/23 [==============================] - 18s 780ms/step - loss: 0.4821 - Faction_loss: 0.2420 - RawSentiment_loss: 0.2402 - Faction_binary_accuracy: 0.8977 - RawSentiment_binary_accuracy: 0.8950\n",
            "6/6 [==============================] - 4s 241ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "23/23 [==============================] - 33s 778ms/step - loss: 1.3248 - Faction_loss: 0.6568 - RawSentiment_loss: 0.6680 - Faction_binary_accuracy: 0.4529 - RawSentiment_binary_accuracy: 0.4475\n",
            "Epoch 2/4\n",
            "23/23 [==============================] - 18s 796ms/step - loss: 1.1353 - Faction_loss: 0.5627 - RawSentiment_loss: 0.5725 - Faction_binary_accuracy: 0.7776 - RawSentiment_binary_accuracy: 0.7572\n",
            "Epoch 3/4\n",
            "23/23 [==============================] - 18s 786ms/step - loss: 0.8117 - Faction_loss: 0.4078 - RawSentiment_loss: 0.4039 - Faction_binary_accuracy: 0.8145 - RawSentiment_binary_accuracy: 0.8226\n",
            "Epoch 4/4\n",
            "23/23 [==============================] - 18s 777ms/step - loss: 0.5726 - Faction_loss: 0.2872 - RawSentiment_loss: 0.2854 - Faction_binary_accuracy: 0.8786 - RawSentiment_binary_accuracy: 0.8881\n",
            "6/6 [==============================] - 5s 244ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "23/23 [==============================] - 33s 777ms/step - loss: 1.2481 - Faction_loss: 0.6266 - RawSentiment_loss: 0.6215 - Faction_binary_accuracy: 0.5307 - RawSentiment_binary_accuracy: 0.5839\n",
            "Epoch 2/4\n",
            "23/23 [==============================] - 18s 796ms/step - loss: 1.2267 - Faction_loss: 0.6155 - RawSentiment_loss: 0.6112 - Faction_binary_accuracy: 0.6999 - RawSentiment_binary_accuracy: 0.6999\n",
            "Epoch 3/4\n",
            "23/23 [==============================] - 18s 786ms/step - loss: 1.0519 - Faction_loss: 0.5317 - RawSentiment_loss: 0.5202 - Faction_binary_accuracy: 0.7667 - RawSentiment_binary_accuracy: 0.7503\n",
            "Epoch 4/4\n",
            "23/23 [==============================] - 18s 776ms/step - loss: 0.6536 - Faction_loss: 0.3254 - RawSentiment_loss: 0.3282 - Faction_binary_accuracy: 0.8595 - RawSentiment_binary_accuracy: 0.8718\n",
            "6/6 [==============================] - 4s 243ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "23/23 [==============================] - 34s 775ms/step - loss: 1.2780 - Faction_loss: 0.6413 - RawSentiment_loss: 0.6366 - Faction_binary_accuracy: 0.4775 - RawSentiment_binary_accuracy: 0.4707\n",
            "Epoch 2/4\n",
            "23/23 [==============================] - 18s 798ms/step - loss: 1.2487 - Faction_loss: 0.6257 - RawSentiment_loss: 0.6230 - Faction_binary_accuracy: 0.6712 - RawSentiment_binary_accuracy: 0.7108\n",
            "Epoch 3/4\n",
            "23/23 [==============================] - 18s 788ms/step - loss: 0.9379 - Faction_loss: 0.4682 - RawSentiment_loss: 0.4697 - Faction_binary_accuracy: 0.7694 - RawSentiment_binary_accuracy: 0.7844\n",
            "Epoch 4/4\n",
            "23/23 [==============================] - 18s 777ms/step - loss: 0.6203 - Faction_loss: 0.3101 - RawSentiment_loss: 0.3103 - Faction_binary_accuracy: 0.8759 - RawSentiment_binary_accuracy: 0.8772\n",
            "6/6 [==============================] - 4s 244ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save_weights('/content/drive/MyDrive/model/joint.h5')"
      ],
      "metadata": {
        "id": "oMlTQmyoX0eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "faction"
      ],
      "metadata": {
        "id": "ClyX6cFF3hwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy)/len(accuracy)}, f1: {sum(f1)/len(f1)}, precision: {sum(precision)/len(precision)}, recall: {sum(recall)/len(recall)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYShH1t8yOwY",
        "outputId": "c269fc2d-726f-4071-ea45-c7e5001fd3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.847119268234735, f1: 0.8464998405934828, precision: 0.8844184440697365, recall: 0.8959919039368245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentiment"
      ],
      "metadata": {
        "id": "LwoM0p-d3jMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy: {sum(accuracy_s)/len(accuracy_s)}, f1: {sum(f1_s)/len(f1_s)}, precision: {sum(precision_s)/len(precision_s)}, recall: {sum(recall_s)/len(recall_s)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXNJ5Vi3yPXt",
        "outputId": "ecad31ec-8728-4993-f856-74ea9059957d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8515027322404372, f1: 0.8509212905041963, precision: 0.8857284044273754, recall: 0.9007328561404633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_ids, test_attention_masks = tokenize_roberta(['John Fetterman is awesome','DrOz is boring'], 128)\n",
        "result = r_model.predict([test_input_ids,test_attention_masks])\n",
        "f,s=result[0],result[1]\n",
        "f,s=tf.math.sigmoid(f).cpu().numpy(),tf.math.sigmoid(s).cpu().numpy()\n",
        "\n",
        "print(\"faction for tweet: \", f[0], f[1])\n",
        "print(\"sentiment for tweet: \", s[0], s[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAry88XG1Ajs",
        "outputId": "af81a0b0-61f4-4978-b3c3-dc4f1211bf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-57-6b2234f3c76f>:4: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.identity instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faction for tweet:  [0.98713243] [0.07715884]\n",
            "sentiment for tweet:  [0.9762982] [0.08260459]\n"
          ]
        }
      ]
    }
  ]
}